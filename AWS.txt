homebrew 
brew search 패키지이름 
brew info 패키지이름 
brew install 패키지이름 
brew upgrade 패키지이름 
brew uninstall 패키지이름 
brew update      // homebrew 업데이트 

목차
- 네트워크 기본 
- VPC?
- VPC 생성하기
- 내가 구성한 VPC위에 인스턴스 올리기
- Bastion Host 만들고 private subnet ec2와 통신하기
- Nat gateway 만들고 private ec2와 연결하기
- vpc endpoint만들고 사용하기
- awscli 설치 및 자격증명
- django project에 AWS rds 연결하기
- EC2에 django 프로젝트 배포하기, docker 만들기, nginx 적용하기
- docker-compose 사용하기
- EC2 로드 밸런서 연결하기
- AWS Route53 , DNS 동작원리
- Route53 Certificate Manager 적용하여, https 사용하기
- Cloudfront 사용하기
- Nginx, Gunicorn, Supervisor 사용하여 자동배포서버 만들기.
- AWS Autoscaling 설정하기
- AWS Container Service
- AWS cli 명령어 작업
- ECS CLI Compose
- AWS KMS(Key Management Service)
- AWS CodeCommit 
- AWS IAM 보안
- 부하 테스트
- Elastic Beanstalk

###################클라우드 유형#########################
IAAS : 하드웨어만 구성된 리소스에서 OS, 미들웨어를 직접구성하고 어플리케이션 구현
PAAS : 미들웨어까지 구성된 리소스에서 어플리케이션과 데이터 부분은 직접 구현
SAAS : 하드웨어 미들웨어 어플리케이션까지 모두 탑재된 리소스를 사용

###################네트워크 기본#########################

ip address 구조 
0.0.0.0 총4파트, 1파트당 8비트 * 4  =  ip의 최대갯수는 2^32 개 

A class ip
  앞에 1파트가 network bit, 이고 나머지 뒤 3파트는 host bit이다. 
  A class는 맨앞 1비트가 0으로 시작해야한다. 즉 A class 네트워크 종류는 2^7개 이며 한네트워크당 2^24개의 ip를 가질 수 있다. 

B class ip 
  앞에 2파트가 network bit 이고 나머지 뒤 2파트는 host bit이다. 
  B class는 맨앞 2비트가 10으로 시작해야한다. 즉 B class 네트워크 종류는 2^14개 이며 한네트워크당 2^16개의 ip를 가질 수 있다. 

C class ip 
  앞에 3파트가 network bit 이고 나머지 뒤 1파트는 host bit이다. 
  C class는 맨앞 3비트가 110으로 시작해야한다. 즉 B class 네트워크 종류는 2^21개 이며 한네트워크당 2^8개의 ip를 가질 수 있다. 

서브넷 : 특정 네트워크를 여러개로 나누는것. 
  211.11.124.0/25  이런식으로 표현된 ip가 서브넷이라고 할 수 있음. 뒤에 /25 숫자는 나눠진 네트워크에서 변하지않는 비트의 갯수를 말함.(CIDR 표기법)
  서브넷 마스크 : 255.255.255.0  이거는 서브네팅(네트워크를 나누는것)을 하지 않은 상태. 255.255.255.128 이거는 /25 로 나눴다는 뜻 

  이러한 기술들은 결국 각 클래스로 나눠진 네트워크를 운영중인 서비스의 규모에 맞게 분할하여 사용하기 위한 기술이다. 
  따라서 이런 기술을 통해서 A Class 네트워크와 같은 매우 큰 네트워크를 작게 나눠서 사용하면서, 낭비되는 IP주소 자원을 최소화하려는 것이 주된 목적이다.

############################################################
############### VPC? (Virtual Private Cloud) ###############
############################################################

특징 
  계정 생성시 default로 VPC를 만들어 줌.
  만들어진 VPC 위에 EC2, RDS, S3등의 서비스 활용가능
  서브넷 구성 가능
    private subnet : 오직 속해있는 VPC 내부에서만 통신가능. 주로 DB같은 중요한 정보를 저장하는 곳으로 씀.
      외부인터넷과 차단되어 있는 특징때문에 mysql과 같은 db프로그램을 다운받고 업그레이드하는 것이 불가능해서, 
      외부인터넷과 연결할 필요가 있을땐 public subnet으로 우회해서 요청을함. 이 서비스를 NAT Instance(EC2), NAT Gateway 라고 함.
    public subnet : 다른 VPC와도 통신가능.
  보안 설정 
  VPC peering(VPC간의 통신)
  IP대역 지정 가능 
  VPC는 하나의 region에만 속할 수 있음.

Region > VPC > AZ > Subnet   
AZ(Availability Zone)는 하나의 region안에 자연재해와 같은 비상상황을 대비하기 위해서 데이터센터를 분리해놓은 거라고 보면 됨. 보통 한 region당 2개이상의 AZ가 존재함.

Internet Gateway (IGW) : 외부 VPC와 통신하기 위한 통로. private subnet은 IGW 와 연결되어있지 않음.

Route Table : 통신을 위해 ip정보를 table로 보내면 table에 정한 규칙대로 특정 ip대역은 local로, 그 외의 ip대역은 IGW로 가라 라는 이정표라고 생각하면됨.
  private subnet은 route table에 igw로 가라는 이정표 자체가 없음.

NACL(Network Access Control List) : 보안 규칙. 특정 ip는 막는다던지 하는. stateless
Security Group : 보안 규칙. stateful
NACL vs Security Group 
  NACL은 인바운드 아웃바운드 설정시. 무조건 설정대로 따르기때문에, 어디서 요청이 들어왔건 간에, 요청이 들어오고 나갈때 이 규칙을 무조건 따르므로 보안이 높음.
  반면 보안그룹은 규칙에 있어서 어디서 요청이 왔는지, 요청종료에 따라 예외로 처리되는 부분들이 있기 때문에 보안이 좀 낮음.

NAT instance, NAT gateway : private subnet에 있는 인스턴스가 외부 인터넷과 통신하기 위해 쓰는 방법. Nat instance는 public subnet에 통신전용 
  instance를 만들어 private subnet의 인스턴스와 외부 인터넷을 연결시켜주는 역할을 한다. NAT gateway는 private ec2의 요청을 NAT gateway가 받아서
  IGW로 연결해 주는 역할을 한다.
Bastion host : 외부 사용자가 private subnet에 있는 인스턴스와 통신하기 위한 방법. Bastion host는 public subnet에 있는 인스턴스임.

VPC endpoint : private subnet 인스턴스가 AWS의 다양한 서비스를 자유롭게 이유할 수 있게 해주는 방법. VPC밖으로 트래픽이 나가지 않음.
  interface Endpoint : private Ip를 활용한 방법.
  gateway Endpoint : route table을 통한 방법

NAT gateway와 endpoint의 차이 : NAT gateway는 igw로 연결되어 트래픽이 외부로 노출되는 반면 endpoint는 트래픽이 외부로 노출되지 않음.

통신맵
internet <=> IGW <=> Router <=> Route Table <=> NACL <=> VPC (public, private)


############################################################
############### VPC 생성하기 ###############
############################################################

VPC는 region마다 default로 하나씩 만들어져 있음. 
VPC는 region마다 구분이 되어있기때문에 서울지역에서 생성한거랑 미국지역에서 생성한거랑 완전히 다름.

-나만의 vpc 하나 따로 생성. IPv4 CIDR 10.0.0.0/16
-vpc를 생성하면 라우팅 테이블, NACL 자동으로 생성됨. Subnet, IGW ,NAT gateway, endpoint는 생성 안됨.
-subnet 생성 
  private subnet : 10.0.1.0/24
  public subnet : 10.0.0.0/24
-IGW생성 : 처음엔 detached 상태임. 아직 어떤 vpc에도 연결이되어있지않은 상태임. 생성한 vpc와 연결.
-rtb는 default로 하나 생성되어있음. 이 기본테이블을 private subnet과 연결시키고, 새로운 rtb를 따로 만들어서 public subnet과 연결.
  이때 public subnet과 IGW를 연결시켜줘야지 외부와 통신을 할 수 있기때문에 라우팅 테이블에 0.0.0.0/0 ip주소가 요청이 오면 igw로 연결되게 설정해줘야함.
  이미 default로 있던 설정 10.0.0.0/16 local은 유지. 이 사이드블록 ip요청은 모두 local로 보내고 그 외에 ip주소는 모두 igw로 연결해줌.

-NACL 설정 : NACL은 VPC만들때 default로 하나 만들어져 있어서 subnet을 만들면 모든 subnet이 이 default nacl을 따르고 있음. 
  private NACL과 public NACL 규칙을 따로 만들어줘야 하기 때문에 , NACL을 새로 하나 생성해서 subnet을 따로 배정해주자.

public NACL 설정 : 
  인바운드 규칙
  규칙번호 100, 사용자 지정 TCP, 포트범위 22, 소스 0.0.0.0/0, 허용
  200, ;;, 80, ;;, ;; 
  300, ;;, 443, ;; ,;;

  보통 포트범위는 0~65535 까지 있음. 1024~65535포트는 임시포트로써 request에 대한 response가 이 임시포트를 사용하게됨.
  포트22는 SSH , 포트80은 HTTP, 포트443은 HTTPS 요청이다.

  여기서 규칙번호는 어떤 요청이 왔을때 체크할 규칙순서라고 보면됨. 즉 번호가 먼저일수록 그 규칙을 먼저 체크를함.
  만약 규칙번호 101로 포트22 거부를 설정추가해도, 이 규칙은 100번 규칙으로 인해 무시가 될 것임.

  아웃바운드 규칙 
  규칙번호 100, 사용자 지정 TCP, 포트범위 1024-65535, 대상 0.0.0.0/0, 허용

  이렇게 설정을 하면 인바운드규칙을 통과해서 들어온 요청에 대해서 모두다 response를 해주겠다는 의미이다. 임시포트를 다 열어줬기 때문.

############################################################
############### 내가 구성한 VPC위에 인스턴스 올리기 ###############
############################################################

1. EC2 서비스 화면으로 이동
2. 인스턴스로 들어가서 인스턴스 시작
3. AMI, 운영체제 선택
4. 인스턴스 유형, 컴퓨터 성능 선택 앞에 t로시작하는지 c로 시작하는지 각 특장점들이 있기 때문에 따로 공부가 필요함.
5. 네트워크 설정
    vpc(virtual private cloud) : 나만을 위한 인스턴스 공간, 프로젝트가 여러개라면 각각 다른 vpc공간을 사용하는것이 권장됨.
      내가 직접 만들어낸 vpc공간을 선택해서 이 위에 ec2를 올릴 수 있음.
    서브넷 : 마찬가지로 내가 구성한 VPC안에 서브넷도 구성해놨으면, 그 서브넷위에 ec2를 세울 수 있음. (public 혹은 private 서브넷)
    퍼블릭 IP 자동 할당 : 공공ip를 할당해서 이 ip를 통해 요청할 수 있게끔, 이거 활성화되어있어야 ec2로 요청보내는 등 테스트 진행가능(private 서브넷은 퍼블릭ip 필요없음)
6. 보안그룹 설정.
    VPC내에서 NACL을 설정해준것과 같이 여기서도 설정가능. 이미 만든 보안그룹이 있으면 그 보안그룹으로 설정.
6. 고급 세부 정보 
    스팟 인스턴스 요청 : 최대로 지불할 요금선을 정해서 그 이상 과금이 안나오게함.
    IAM : collaborator 설정 
    storage: 8GiB 기본, 범용 SSD 기본
7. 인스턴스 개수 : 서버개수 설정

8. 키페어 : 키페어 pem 파일이 있어야 서버 접속가능 

############################################################################
############### Bastion Host 만들고 private subnet ec2와 통신하기 ###############
############################################################################

public subnet에 ec2(bastion host) 만들기. 퍼블릭 IP 활성화, 키페어 등록/생성 
보안그룹설정 : public ec2에서 private ec2로 접속할 것이기 때문에 public ec2에 ssh 포트 22만 열어줘도 됨. 모든 ICMP도 열어줘도 무방.

private subnet에 ec2 만들기. 퍼블릭 Ip 비활성화. 키페어 등록/생성 
**보안그룹설정 : public ec2에서의 ssh요청을 받을 것이므로 SSH 포트22번에 사용자지정 public 보안그룹만 허용 설정.
              모든 ICMP 0-65535 포트 사용자지정 public 보안그룹만 허용 설정.

**이때 public subnet의 NACL설정에서 만약 모든트래픽허용을 안해주고 SSH만 허용해줬으면 private ec2에서 오는 응답(응답포트는 ssh포트와 다르기때문)을 못받기때문에 통신이 안된다.

이후 public ec2에 private ec2 keypair 파일 저장하기 : scp -i publickeypair.pem privatekeypair.pem ec2-user@퍼블릭ip:/home/ec2-user
public ec2 ssh 접속 -> public ec2에서 private ec2 ssh 접속.

### windows 에서는 pageant putty 검색 -> pageant putty puttygen 설치 
puttygen : pem파일을 ppk로 변환
pageant : ppk로 변환된 pem파일 등록 
putty : public ip 주소를 ip address에 복붙, ssh체크 => 옆에 ssh-Auth에서 allow agent forwarding 체크 => connection-data에서 username ec2-user설정 
      =>설정값 저장하고 open 누르기 => 커맨드창에 ssh privateIP 입력 



###########################################
Nat gateway 만들고 private ec2와 연결하기
###########################################
Nat gateway 생성 : public subnet에 생성. 탄력적 IP 할당. 연결유형 퍼블릭 
private subnet의 routing table에 가서 0.0.0.0/0의 요청을 위에 만든 nat gateway로 보내주는걸로 설정추가. natgateway는 이를 igw로 연결
이렇게 하면 private ec2에서 sudo yum install mysql 같은 명령어 수행가능 
// EC2 -> 탄력적 IP -> 탄력적 IP 할당 -> IP연결(내가 생성한 인스턴스에 연결)


###########################################
vpc endpoint만들고 사용하기
###########################################
private ec2에서 s3서비스와 같은 AWS서비스를 외부트래픽 유출없이 사용하고 싶을때 사용 
IAM 역할 생성 : s3 fullaccess 역할 만들기.
바스티온 호스트(public ec2)와 private ec2(**s3 IAM 권한 줘야함) 생성
S3 생성
  버킷이름 설정
  리전 설정
  퍼블릭 액세스 차단 설정 : 체크해야지 나만 접근가능 해제하면 모든 유저가 다 들어와서 볼수있기때문에 치명적임. 추후에 IAM 관리를 통해서 접근가능한 유저 설정 가능.
  버킷 버전 관리 : git과 같이 버전 관리를 통해 일정 시점으로 롤백할 수 도 있는 기능. 비활성화 
private ec2 접속.
aws s3 ls --region [region위치]   : 해당 region에 있는 s3 버켓 리스트 보여줌. 이때 원래 이게 안되야 정상. endpoint없이 이게 된다는 것은 라우팅 테이블에 
  nat gateway가 설정되어있기때문임. 이는 외부에 트래픽이 노출되므로 s3전용 endpoint를 만들어 s3관련 요청은 endpoint를 사용하게 설정해야함.
vpc endpoint생성
  서비스에서 s3검색. 리전에 맞는 s3 gateway 선택 
  vpc선택 
  라우팅 테이블은 private 전용 테이블로 체크하고 생성.
  그러면 라우팅 테이블에 endpoint관련 설정이 자동으로 추가되어있음.
private ec2에서 다시 aws s3 ls --region [region위치] 입력하면 이제 nat gateway가 아닌 vpc endpoint를 사용하게 됨.
  






##################################################################################################
################################  awscli 설치 및 자격증명  #####################################
##################################################################################################
awscli 설치 
https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-started-install.html
ubuntu (sudo apt install awscli)
aws --version
aws help 
aws ec2 help


aws 무료계정가입
aws 액세스키 생성하기 
내 계정 클릭 후 보안 자격증명 들어가기 
액세스키 생성. csv파일 생김. 

### 자격증명하기 
vi ~/.aws/credentials 
[default]
aws_access_key_id=
aws_secret_access_key=

vi ~/.aws/config
[default]
region=us-west-2
output=json

aws configure 로  키와 시크릿 등 자격증명 설정 가능 
aws sts get-caller-identity   내 자격증명 확인하기 
aws ec2 describe-key-pairs    내 ec2에 등록된 key pair 목록 불러오기 

aws configure --profile [profileName]   새 profile 설정하기 

aws configure get region   default 지역 가져오기 
aws configure get region --profile [profileName]

export AWS_PROFILE = [profileName]  환경변수 설정 (default가 이 프로필로 바뀜 )

MFA 설정 : otp 만드는거라고 생각하면 됨.






비용 발생시 경보 생성.
db관련 과금 주의사항
https://velog.io/@arara90/AWS-Free-tier%EB%A1%9C-RDS-%EC%82%AC%EC%9A%A9-%EC%A4%91-%EC%9A%94%EA%B8%88%EC%9D%84-%EC%A7%80%EB%B6%88%ED%96%88%EC%96%B4%EC%9A%94
계정의 결제 대시보드로 이동  결제기본설정에서 프리티어 사용량 알림받기 설정, 결제 알림받기 설정 체크 
이후 cloud watch서비스로 이동해서 경보 -> 결제로 이동후 새 경보생성한다. 이후 지표선택후에 경보생성.
sns를 이메일로 설정했으면 , 인증메일올텐데 거기서 컨펌눌러야 경보가 오게됨.

aws 비용 계산기 
https://calculator.aws 

리소스 정리해주는 오픈소스
aws-nuke 

프리티어 계정이 만료가 되면, bippr0901+a@gmail.com 이런식으로 새 계정을 만들어 주면 bippr0901이메일로 동일하게 이메일을 받을 수 있고, 
프리티어 계정을 새로 만들수있음. 


AWS 주요 서비스들 
AWS EC2 : 가상의 컴퓨팅 서비스 
AWS Lightsail : 가상의 프라이빗 서버 
AWS Auto Scaling : 서버 사용량이 증가하면 자동으로 서버 증설, 감축 해주는 서비스 
AWS Workspace : 회사 문서들을 가상의 공간에 저장하는 서비스 

AWS Route53 : 내 서버와 domain을 연결해주는 서비스 
AWS VPC : 가상의 네트워크 서비스 
AWS Direct Connect : 실제 물리적컴퓨터와 가상의 컴퓨터를 연결하여 정보전달하게 해주는 서비스 
AWS ELB : 부하분산 서비스 (Auto scaling과는 약간 종류가 다름 )

AWS S3 : 여러가지 파일을 형식에 구애 받지 않고 저장 
AWS RDS : 관계형 DB 서비스 
AWS DynamoDB : NoSQL DB 서비스 
AWS ElasticCache: in-memory 기반의 cache 서비스 (redis같은거)

AWS Redshift : 데이터 분석에 특화된 스토리지 시스템 
AWS EMR : 대량의 데이터를 효율적으로 관리할 수 있게 해주는 서비스 
AWS Sagemaker : 머신러닝 데이터분석을 위한 클라우드 환경 제공 

EC2 서비스 : AWS 서버를 만들 수 있는 곳 
    인스턴스 : 서버

    네트워크 및 보안
        탄력적 IP : AWS에서 ip를 하나 받아서 내 인스턴스와 연결을 할 수 있음.
        보안 그룹 
            인바운드 규칙 : 내 서버에 어떤 요청을 허용할것인지, 특정ip만 요청할 수 있게 하는 등, 보안설정

    로드 밸런싱
        로드 밸런서 : 서버에 부하가 걸렸을때, 똑같은 서버를 자동으로 늘리고 줄이는 규칙을 설정하는 곳, 여러 서버에 트래픽을 자동으로 분산시켜줌.
        L4: client요청이 왔을때 어떤 데이터인지는 보지않고, 그냥 ip만 분산해줌. 비용저렴.  속도 빠름.
        L7: 요청이 왔을때 어떤요청인지 확인을하고 스마트하게 분산시켜줌. 속도 문제, 비용문제 




인스턴스 연결
1. EC2 인스턴스 연결 : 그냥 연결누르면 됨. 
2. SSH 클라이언트 연결 : pem 파일 있는 위치로 가서, aws 사이트 ssh 클라이언트 연결부분에 적혀있는 명령어들 실행 , 
    chmod는 pem파일의 접근permission 설정하는 명령어임.   ls -al 하면 현재 파일들의 permission 설정들을 볼 수 있음.
    명령어 다 입력하면 fingerprint 물어보는데 yes 하면 됨.

인스턴스 중지, 종료.
인스턴스를 중지를 해도 비용은 계속 발생함. 종료(삭제)를 해야지 비용발생이 안됨.
스냅샷 기능은 삭제한 인스턴스가 다시 필요해질 상황을 대비해서 미리 백업을 해두는 기능. 비용발생.


S3 
파일,폴더 업로드하기 (올라가는 파일들을 객체라고 표현을 함.)
권한 : 파일마다 접근권한을 설정해줄수있음
속성 : 스토리지 클래스는 보통 standard로 설정을 하고 자주 안꺼내보는 파일들은 밑에목록들을 사용하면됨. 비용이 저렴해짐.
업로드가 되면 객체에 파일에 들어가서 속성을 확인할 수 있음. 이때 url이 뜨게 되는데 여기로 접속을 해도 퍼블릭 액세스를 막아놨기때문에 다운로드가 안됨.
하지만 버켓 퍼블릭액세스를 풀고, 객체 액세스도 풀면  저 url로 들어갔을때 파일이 다운로드가 됨.



aws-sdk?  사용하기 (nodejs에서 s3 버켓에 있는 파일들 불러서 쓰거나, 파일을 업로드할때 사용)
npm 프로젝트 폴더 생성
npm install @aws-sdk/client-s3
s3 버킷 접근하기 위한 IAM 설정 필요 
aws iam 서비스로 들어가서 사용자 추가 
    사용자 이름 설정
    AWS 액세스 유형선택 : 액세스 키 방식(key,secret) , 암호 방식 (그냥 비밀번호 치고 들어가기)
    권한설정 부분에서 s3 검색시 , full access , read only 등 다양한 접근권한 종류가 있음 원하는 권한 체크후 생성


플젝 폴더에서 libs 폴더 생성 후 s3Client.js 파일 생성
const { S3Client } = require("@aws-sdk/client-s3");
// Set the AWS Region.
const REGION = "us-east-1";
// Create an Amazon S3 service client object.
const s3Client = new S3Client({
  region: REGION,
  credentials: {
    accessKeyId: "",
    secretAccessKey: "",
  },
});

module.exports = { s3Client };


플젝 메인 위치에서 index.js 파일 생성
const { ListBucketsCommand } = require("@aws-sdk/client-s3");
const { s3Client } = require("./libs/s3Client");

const run = async () => {
  try {
    const data = await s3Client.send(new ListBucketsCommand({}));
    console.log("Success", data.Buckets);
    return data; // For unit tests.
  } catch (err) {
    console.log("Error", err);
  }
};
run();


RDS? 
데이터베이스 생성하기 
1. DB 종류 선택
2. DB 인스턴스 식별자 : 기본 이름말고 알아보기 쉬운 이름 설정 권장.
3. 퍼블릭 설정 : 퍼블릭으로 열어줘야 사용자이름과 암호, 엔드포인트만 있으면 어느 곳에서든 디비접속가능
default로 생성
4. 보안설정 인바운드 규칙에서 포트를 열어줘야지 mysql workbench라던지 postgresql pgamdin 으로 연결이 가능함.
5. DB username과 password 기억해놓기 

모놀리식 아키텍쳐 vs 마이크로서비스 아키텍쳐 
모놀리식은 소규모 프로젝트에 적합. 
마이크로서비스는 기능마다 독립적으로 분리하여 유지보수가 쉽게 설계하는것. 대규모 프로젝트에 적합.






############################################################################
###############  django project에 AWS rds 연결하기  ###########################
############################################################################

1. settings.py에 생성한 DB의 name, username, password, host 주소 , port 입력
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.mysql',
        'NAME': 'fastcampus',
        'USER': 'hongsa',
        'PASSWORD': 'Dnjfchs23',
        'HOST': 'testhongmysql.cpikzej9kpmo.us-east-1.rds.amazonaws.com',
        'PORT': '3306',
        'OPTIONS': {
            'init_command' : "SET sql_mode='STRICT_TRANS_TABLES'"
        }
    }
}

2. brew install mysql, pip install mysqlclient  만약 brew install mysql 먼저 안하면 client설치 오류남.
3. ubuntu 환경에서는 sudo apt-get install libmysqlclient-dev 해주고 mysql 설치하면 됨.
4. python3 manage.py migrate 해주면 db와 연결완료 


############################################################################
###############  EC2에 django 프로젝트 배포하기, docker 만들기, nginx 적용하기 #################################
############################################################################

- ubuntu EC2 인스턴스 생성. 보안규칙 : SSH 22포트 모든ip, 사용자 지정 TCP 8000포트 모든 ip
- 인스턴스 연결
- sudo apt-get update
- sudo apt-get install build-essential  : 개발에 필요한 패키지 모음. 소스 컴파일러(GCC) 설정이나 의존성 해결하는 configure,make 명령어 등
- sudo apt-get install python3
- django settings에 ALLOWED_HOSTS 부분에 ec2 public dns 주소넣어주고, project github 레포지토리 생성.
- ssh-keygen -t rsa : passphrase 비밀번호도 생성. 이게 github의 deploy key가 될것임.
- cd .ssh , cat id_rsa.pub : key 복사 후 github 레포지토리 setting에 deploy key 생성.
- ssh-keygen -t rsa -C "내깃헙이메일" : overwrite 
- cat id_rsa.pub : 복사해서 내 깃헙 "계정"의 settings에 SSH and GPG keys 목록으로 가서 ssh 키 생성
- ec2에서 mkdir [프로젝트이름] , git clone [레포지토리SSH주소] : passphrase 입력하면 clone됨.
- sudo apt-get install virtualenv
- 내 프로젝트 작업폴더에서 virtualenv -p python [가상환경이름]
- source 가상환경이름/bin/activate
- sudo apt-get install python3-pip
- db mysql 사용시 : sudo apt-get install libmysqlclient-dev
- (docker) vi requirements.txt => uwsgi 추가. 
- pip install -r requirements.txt 
- python3 manage.py runserver 0.0.0.0:8000
- 인터넷에서 ec2 퍼블릭 dns 주소:8000 접속해보면 완료
- 만약 접속이 안된다면, 연결한 db에도 접근이 가능한상태인지 확인.

- ctrl-z , bg, disown -h  : 이렇게 하면 ec2 logout 해도 서버가 계속 백그라운드로 돌아감. 이거 안하면 logout시 서버도 같이 꺼짐.
- ps -ef | grep python : 현재 작업중인 python 파일들을 보여줌. 이 작업들에 아이디 번호가 있는데 kill -9 아이디번호 해주면 작업 강제종료.

- (docker) curl -fsSL https://get.docker.com/ | sudo sh
- (docker) sudo usermod -aG docker $USER      : 권한설정에 관한 부분임 
- (docker) docker --version
- (docker) vi Dockerfile (프로젝트 폴더 안에 생성)
아래내용 붙여넣기
FROM python:3.10.6

ENV PYTHONUNBUFFERED 1

RUN apt-get -y update
RUN apt-get -y install vim

RUN mkdir /srv/docker-django
ADD . /srv/docker-django

WORKDIR /srv/docker-django

RUN pip install --upgrade pip
RUN pip install -r requirements.txt

EXPOSE 8000
CMD ["python","manage.py","runserver","0.0.0.0:8000"]

#nginx 쓸거면 마지막 두줄은 빼야됨.
# ADD . 부분은 docker container에 /srv/docker-django 경로를 만들거고 여기에 내 로컬서버에 있는 작업폴더내용들을 모두 넣겠다는 뜻.
# WORKDIR는 여기서 실행할거라는 뜻.
#################################

docker build -t docker/django .     #여기서 docker/django는 이미지 이름임. build는 도커이미지 생성하라는 명령어.
docker image list    내가 만든 도커이미지 목록보기 
docker image rm --force imageID
docker run -d -p 8000:8000 docker/django     docker/django라는 이름으로 컨테이너를 실행시키라는 뜻.
  -d는 백그라운드로 실행하라는 뜻
  -p는 포트라는 뜻. 8000:8000은 8000번 포트로 요청이 왔을때 8000번포트로 연결시켜주라는 뜻.

docker ps : 현재 실행되고 있는 docker container들 상태확인. container-id 확인가능
docker stop cotainer-id 


##### nginx 적용  #####
프로젝트 폴더에서 vi uwsgi.ini
아래내용 붙여넣기
[uwsgi]
socket = /srv/docker-django/django.sock
master = true

processes = 1
threads = 2

chdir = /srv/docker-django
module = deliveryProject.wsgi
# deliveryProject : project folder name

logto = /var/log/uwsgi/uwsgi.log
log-reopen = true

vacuum = true
###########################

(nginx) ~경로에서 mkdir nginx 
cd nginx 
### vi nginx.conf 
아래내용 붙여넣기

user root; 
worker_processes auto;
pid /run/nginx.pid;

events {
  worker_connections 1024;
}

http {
  sendfile on;
  tcp_nopush on;
  tcp_nodelay on;
  keepalive_timeout 65;
  types_hash_max_size 2048;

  include /etc/nginx/mime.types;
  default_type application/octet-stream;

  ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE
  ssl_prefer_server_ciphers on;

  access_log /var/log/nginx/access.log;
  error_log /var/log/nginx/error.log;

  gzip on;
  gzip_disable "msie6";

  include /etc/nginx/sites-enabled/*;
}
###############################


### vi nginx-app.conf 

upstream uwsgi {
  server unix:/srv/docker-django/django.sock;
}

server {
  listen 80;
  server_name localhost;
  charset utf-8;
  client_max_body_size 128M;

  location / {
    uwsgi_pass uwsgi;
    include uwsgi_params;
  }

  location /media/ {
    alias /srv/docker-django/.media/;
  }

  location /static/ {
    alias /srv/docker-django/.static/;
  }
}
###########################

### vi Dockerfile 

FROM nginx:latest

COPY nginx.conf /etc/nginx/nginx.conf
COPY nginx-app.conf /etc/nginx/sites-available/

RUN mkdir -p /etc/nginx/sites-enabled/\
  && ln -s /etc/nginx/sites-available/nginx-app.conf /etc/nginx/sites-enabled/

EXPOSE 80
CMD ["nginx", "-g", "daemon off;"]
##############################

docker build -t server_dev/nginx .
docker run -d -p 80:80 server_dev/nginx



###########################################
docker-compose 사용하기 
###########################################
~ 경로에서  (projectFolder랑 nginx폴더가 위치해있는 경로에서)
sudo curl -L "https://github.com/docker/compose/releases/download/v2.1.1/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

### vi docker-compose.yml

version: '3'
services:

  nginx:
    container_name: nginx 
    build: ./nginx 
    image: docker-django/nginx 
    restart: always
    ports:
      - "80:80"
    volumes:
      - ./deliveryProject:/srv/docker-django
      - ./log:/var/log/nginx 
    depends_on:
      - django
  
  django:
    container_name: django 
    build: ./deliveryProject
    image: docker-django/django 
    restart: always 
    command: uwsgi --ini uwsgi.ini 
    volumes:
      - ./deliveryProject:/srv/docker-django 
      - ./log:/var/log/uwsgi

# depends_on 설정은 django라는 컨테이너가 없으면 실행하지 말라는 의미. 즉, django 먼저 실행시키라는뜻.
#############################

docker image rm --force imageID   : 기존에 있던 컨테이너 이미지 삭제하기 
 docker stop $(docker ps -a -q)  모든 컨테이너 중지
 docker rm $(docker ps -a -q)    모든 컨테이너 지우기
 docker rmi $(docker images -q)  모든 이미지 지우기

docker-compose up -d --build 
docker-compose ps


###########################################
EC2 로드 밸런서 연결하기
###########################################
대상 그룹 만들기 : 대상그룹이란 EC2 서버들의 집합체이다. 마이크로서비스같은경우 기능마다 서버가 분리되어있으므로 이를 관리하기 위해서 서비스마다 대상그룹을 만듬.
    대상그룹설정에서 instance체크
    port설정은 로드밸런서가 이 대상그룹에 어떤 포트로 요청을 보내줄것인지에 대한 설정임(EC2의 보안그룹 인바운드 포트번호) 즉 대상그룹마다 각각의 다른포트를 정해줘야함.
    대상그룹마다 포트가 다 다르기때문에 추후에 대상그룹이 더 생기면 로드밸런서 리스너에서도 새로 만든 대상그룹을 추가 해주고 규칙을 수정해줘야함.
    
    HTTP1 체크
    health check : 로드 밸런서가 이제 대상그룹안에 있는 서버들에게 요청을 보낼 때, 어떤 서버는 죽어있을 수 있기 때문에 살아있는지 체크를 해보는거임.
      특정 url주소로 한번 요청을 해보고 응답이 오는지 테스트를 하는 과정. path에는 /order/shops  이런 주소를 적어주면됨.
      이때 health check를 할때 EC2의 private ip로 보내므로 이 주소를 ALLOWED_HOSTS에 추가해줘야함.
로드 밸런서 생성 : 
  Application load balancer(L7)로 생성 
  internet-facing
  IPv4 
  VPC, vpc AZ 체크
  로드밸런서가 요청받을 포트번호 80
  보안그룹설정 : 인바운드 80포트로 오는 모든 요청허용, 아웃바운드 모든 트래픽허용
  내가 만든 대상그룹과 연결.
** 생성되면 나오는 로드 밸런서의 퍼블릭 dns 주소를 ec2 장고 프로젝트의 settings.py  ALLOWED_HOSTS에 추가

EC2 AMI 생성 :
  현재 실행중인 EC2의 모든 컴퓨터환경과 똑같은 AMI(amazon machine image)을 생성할 수 있다.(안에있는 모든 파일들도 포함해서 복제함.)
  인스턴스 작업에서 이미지 템플릿 -> 이미지 생성 
  생성된 이미지 오른쪽 클릭 인스턴스 생성
  이후 대상 그룹에 추가 가능

ALB Rule 설정 :
마이크로서비스에서는 서비스 기능별로 (/order, /delivery) 대상 그룹(target group)을 만들고, 각각의 대상그룹안에 여러개의 서버를 구성해놓는다.
로드 밸런서는 이제 /order로 요청이오면 대상그룹1로 보내고, /delivery로 오면 대상그룹2로 보내는 gateway 역할을 하게 된다.(ALB Rule)
  로드 밸런서누르고 리스너 항목에 보면 규칙 보기/편집 클릭 
  규칙 + 버튼 누르고 새로운 규칙에 경로(/delivery)와 대상그룹 선택하고 규칙 추가.

Sticky Session : 로그인을 하고나서 새로고침을 누르면 계속 로그인이 유지되어있어야하는데 타겟그룹내에 서버가 여러개이다 보니까 로드밸런서가 새로고침할때마다
  다른 서버로 요청을 보낼 수 있고, 그럴때마다 session이 저장되어있지않은 서버에서는 다시 로그인을 해야되는 상황이 생긴다. sticky session은 
  타겟그룹내의 서버에 session을 저장하는것이 아닌 로드밸런서에 session을 저장해서 이런 상황을 막고자 하는 기능이다.



###########################################
AWS Route53 , DNS 동작원리
###########################################
도메인을 등록하려는 사람(hongsa.com)이 등록대행자에 도메인과 ip주소 전달 => 등록대행자(Aws Route53)는 DNS server에 hongsa.com은 어떤 ip와 연결할것인지에 
  대한 정보를 db 저장하고 도메인 등록소에 전달 => 도메인 등록소 Top level domain db에 이 정보를 저장 후 ICANN이라는 국제표준기구로 전달 => 
  ICANN은 Root name server에 이 정보들 저장.

client가 hongsa.com에 접속을 시도했을때 ICANN으로 처음 요청을 보냄 => ICANN은 다시 등록소의 Top level domain에서 hongsa.com은 어떤 ip인지 찾아와서
client에게 전달해준다.

Aws route53에서 도메인 등록. 1년 2만원 정도. 
도메인 등록되면 호스팅 영역에 내 도메인 생성됨. 
레코드에서 유형 IPv4, 라우팅정책은 단순라우팅으로 설정. 실제 로드밸런서 dns주소나 ec2 ip주소, 혹은 cloudfront를 등록하면 내가 등록한 도메인으로 접속시 연결이 됨.
만약 로드밸런서 포트를 80포트가 아닌 다른 포트로 설정했다면 domain.com:port 를 쳐줘야 연결이 가능함.
추가로 django 프로젝트 settings.py ALLOWED_HOSTS에도 domain 등록을 해줘야함.



###########################################
Route53 Certificate Manager 적용하여, https 사용하기 
###########################################
https는 http와 달리 client와 server간의 오가는 데이터들을 암호화해서 보내기 때문에 보안성이 뛰어나다.
단점은 속도가 느려짐

https를 사용하기 위해서는 서버보안인증서를 route53에 적용시켜줘야지 https를 사용할 수 있다.

AWS Certificate Manager로 이동
인증서 요청 , 퍼블릭 인증서로 요청
내 도메인 입력 honglion.com , www.honglion.com
검증방법 : 이거같은 경우 honglion.com이 내가 구매한 도메인이라는 것을 어떻게 증명할지에 대한 설정이다.
    DNS 검증방식 선택 
이후 내가 인증서를 요청한 도메인마다 Route53에 CNAME 레코드를 생성해주면 알아서 검증해줌.
검증이 되고 정상발급되면 로드밸런서에서 HTTPS 리스너를 추가해줘야한다.
리스너 추가:
  HTTPS 443 포트
  기본작업, 전달대상(Forward to) 설정 
  security policy 기본선택
  기본 SSL 인증서 : 내가 방금 만든 도메인 인증서 선택



###########################################
Cloudfront 사용하기
###########################################
Cloudfront = Cache + CDN 
서버가 어느 지역에 위치해 있든지, 전세계사람들이 빠르게 내 서버를 이용할 수 있게 해줌.
  Cache : client가 요청할때마다 origin서버에서 계산해서 응답해주는 것이 아닌, 미리 연산된 값을 Cache서버에 저장해놓고
  그 값을 client가  요청해올때마다 전달해주는 방식.
  이렇게 되면 Cache서버는 새로 업데이트된 정보를 전달못해주는 문제가 발생하는데, 이를 해결하기위해 Cache서버를 일정시간간격으로
  업데이트해줘서 이런 문제를 방지한다(TTL 설정)

  CDN(Content Delivery Network) : 미국에서 한국서버에 요청을 하면 응답시간이 길지만 한번 저장된 정보를 미국의 cache서버(edge location)에 저장해놓으면
    client가 다음에 요청할때 미국 cache서버에 요청을 하게되기때문에, 어느 위치에 있든 속도가 매우 빨라진다.

Cloudfront 생성하기 :
  AWS Cloudfront에 가서 생성 
  원본 도메인은 : 내 ALB로 설정
  엣지로케이션은 모든 지역선택시 비용높음. 
  대체 도메인 이름 (CNAME)에 honglion.com, www.honlion.com 추가 
  캐시키 및 원본요청에서 legacy cache settings에서 customize TTL설정은 몇초마다 한번씩 캐시서버가 원본데이터 요청을 할 것인지에 대한 설정임.
  SSL 인증서에 내 AWS Certificate Manager 인증서 선택.
  나머지 설정값은 우선 기본으로 설정해서 생성.
  이후 Route53에 가서 내 도메인 레코드에서 honglion.com, www.honlion.com IPv4유형 별칭 설정을 ALB에서 Cloudfront로 바꿔줘야함.

client와 server 간의 로드맵 
client => Route53, Certificate Manager => Cloudfront => ALB => EC2 


##################################################
Nginx, Gunicorn, Supervisor 사용하여 자동배포서버 만들기.
##################################################
인스턴스 생성.
sudo apt update
sudo apt-get update 
sudo apt-get install python3-pip 
sudo pip3 install gunicorn 
sudo apt-get install supervisor 
sudo apt-get install nginx 
sudo pip3 install django 
django-admin startproject [project_name] 
cd [project_name] 
vi [project_name]/settings.py  : ALLOWED_HOSTS 에 "*" 추가

cd /etc/supervisor/conf.d/ 
sudo touch django.conf 
sudo vi django.conf

###아래 내용복사해서 붙여넣기###
[program:gunicorn]
directory=/home/ubuntu/[project_name]
command=/usr/local/bin/gunicorn --workers 3 --bind unix:/home/ubuntu/[project_name]/app.sock [project_name].wsgi:application
autostart=true
autorestart=true
stderr_logfile=/logs/gunicorn.err.log
stdout_logfile=/logs/gunicorn.out.log

###python3 manage.py runserver 0.0.0.0:8000### 요거는 webserver를 사용할것이라서 안적어도 됨.

sudo mkdir /logs   : 경로 맨처음(home, usr, opt 폴더 있는곳)에 logs 폴더생성. 
sudo supervisorctl reread :  gunicorn:available 뜨면 됨.
sudo supervisorctl update :  gunicorn:added process group 뜨면 됨.
cd /etc/nginx 
cd sites-available
sudo touch django.conf 
sudo vi django.conf 

#### 아래 내용 복사붙여넣기 ####
server{
  listen 80;
  server_name *.compute.amazonaws.com;
  location / {
    include proxy_params;
    proxy_pass http://unix:/home/ubuntu/[project_name]/app.sock;
  }
}
#### 80번 포트니까 ec2 보안그룹에서도 80번포트를 열어줘야 접속가능함

sudo ln django.conf /etc/nginx/sites-enabled/
sudo service nginx restart 
(sudo service nginx stop)

nginx 구동까지 마친상태에서 이 EC2의 AMI를 생성하고 ec2를 만들면, 별도의 설정작업필요없이 서버가 자동으로 구동되어있어서 바로 접속이 가능해진다.



##################################################
AWS Autoscaling 설정하기
##################################################
인스턴스 이미지 생성하기(nginx가 적용되어 있는 인스턴스)
ec2 시작템플릿 만들기 : 
  autoscaling 기능 체크 
  만들어놓은 인스턴스 AMI를 연결
  그 외 컴퓨터 사양들 설정.
이렇게 하면 autoscaling으로 서버를 늘릴때 자동으로 이 시작템플릿 설정으로 ec2를 만들어냄.
Auto scaling 그룹생성 
시작 템플릿 선택후 버전선택(버전은 내가 템플릿 설정을 수정할때마다 버전이 올라가는데 수정 전 버전을 선택할 수 도 있음.)
vpc는 내가 만든 vpc있으면 거기로 하면되고 없으면 default 네트워크는 가용 할 수 있는 서브넷 모두 선택 
로드밸런서에 연결하는게 좋음. 안그러면 나중에 우후죽순으로 생겨나면 관리가 어려워짐, 대상그룹도 선택
상태확인 ELB 체크 , Cloud watch 활성화
그룹크기는 인스턴스를 자동으로 생성할때 생성할수있는 최소 최대 갯수를 의미함.
크기조정정책 :
  cpu 사용률이 어느정도됐을때 auto scaling을 발동할 것인지에 대한 설정
  워밍업 시간이란 인스턴스가 생성되고나서 세팅하는시간이 어느정도 필요하기 때문에 그 유휴시간을 얼마나 둘것이냐에 대한 설정값임.
  축소 비활성은 인스턴스를 늘리기만하고 줄이진않겠다는 뜻 


##################################################
AWS Container Service  
##################################################
클러스터 생성
  네트워킹 전용으로 생성
  vpc 설정안해도됨.
  cloud watch 체크 
  
작업정의
  fargate




##################################################
AWS cli 명령어 작업 
##################################################
로그인
aws ecr get-login --no-include-email --region [region]

ecr 레포지토리 생성 및 이미지 푸쉬 
https://docs.aws.amazon.com/ko_kr/AmazonECR/latest/userguide/getting-started-cli.html
aws ecr create-repository \
    --repository-name repo-cli \
    --region us-east-1

ecs 클러스터 생성 및 작업정의 생성
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/developerguide/ECS_AWSCLI_Fargate.html
https://docs.aws.amazon.com/ko_kr/AmazonECS/latest/userguide/task_definition_parameters.html   작업정의 파라미터

클러스터 생성
aws ecs create-cluster --cluster-name [clusterName]

작업정의 생성하기전 ecr image에 접근할 수 있는 권한이 있어야함 
https://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_execution_IAM_role.html
작업정의 설정 파일 fargate-task.json 에서 
"executionRoleArn":"[IAM 역할 이름]",   추가 

작업정의 생성(작업정의에서는 내가 사용할 images들 설정함)
aws ecs register-task-definition --cli-input-json file://./json-list/fargate-task.json

작업정의 나열
aws ecs list-task-definitions

서비스 생성
aws ecs create-service --cluster [clusterName] --service-name [serviceName] --task-definition [taskName] --desired-count 1 --launch-type "FARGATE" --network-configuration "awsvpcConfiguration={subnets=[[subnetID]],securityGroups=[[보안그룹ID]],assignPublicIp=ENABLED}"

aws ecs create-service --cluster fargate-cluster --service-name fargate-service --task-definition delivery-task:1 --desired-count 1 --launch-type "FARGATE" --network-configuration "awsvpcConfiguration={subnets=[subnet-0970044040934a650],securityGroups=[sg-07aae20b9db6201ed],assignPublicIp=ENABLED}"


서비스 나열
aws ecs list-services --cluster [clusterName]
ARN 가져오기
aws ecs list-tasks --cluster [clusterName] --service [serviceName]
ENI ID 가져오기 
aws ecs describe-tasks --cluster [clusterName] --tasks [ARN]
Public IP 가져오기 
aws ec2 describe-network-interfaces --network-interface-id [ENI]

서비스 삭제
aws ecs delete-service --cluster [clusterName] --service [serviceName] --force
클러스터 삭제
aws ecs delete-cluster --cluster [clusterName]



##################################################
ECS CLI Compose   https://github.com/aws/amazon-ecs-cli
##################################################
macOS 환경
sudo curl -Lo /usr/local/bin/ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-darwin-amd64-latest
brew install gnupg

linux 환경 
sudo curl -Lo /usr/local/bin/ecs-cli https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest
sudo apt-get install gnupg 

mkdir keys 
cd keys 
vi amazon-ecs-public-key.gpg
https://github.com/aws/amazon-ecs-cli/blob/mainline/amazon-ecs-public-key.gpg   안에 내용 붙여넣기 
gpg --import amazon-ecs-public-key.gpg

macOS
curl -o ecs-cli.asc https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-darwin-amd64-latest.asc
Linux
curl -o ecs-cli.asc https://amazon-ecs-cli.s3.amazonaws.com/ecs-cli-linux-amd64-latest.asc

gpg --verify ecs-cli.asc /usr/local/bin/ecs-cli
sudo chmod +x /usr/local/bin/ecs-cli
ecs-cli --version

ecs cli 설치완료후 
sudo apt install awscli
aws configure 설정 
aws ecr get-login-password --region us-east-1
프로젝트 이미지, nginx 이미지를 각각의 ECR에 push
aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/service-role/[정책이름] --role-name [역할이름]

ecs-cli up --empty --cluster [clusterName]

ecs-cli configure profile --profile-name hong_profile --access-key [$AWS_ACCESS_KEY_ID] --secret-key [$AWS_SECRET_ACCESS_KEY]
ecs-cli configure --cluster cli-cluster --region us-east-1 --config-name cluster_config --default-launch-type FARGATE

ecs-cli configure default --config-name cluster_config
ecs-cli configure profile default --profile-name hong_profile

docker-compose.yml 수정
version: '3'
services:

  nginx:
    build: ./nginx 
    image: 536776124305.dkr.ecr.us-east-1.amazonaws.com/docker-compose-nginx:latest
    restart: always
    ports:
      - "80:80"
    volumes:
      - /srv/docker-django
      - /var/log/nginx 
    depends_on:
      - django
  
  django:
    build: ./deliveryProject
    image: 536776124305.dkr.ecr.us-east-1.amazonaws.com/docker-compose-django:latest
    restart: always 
    command: uwsgi --ini uwsgi.ini 
    volumes:
      - /srv/docker-django 
      - /var/log/uwsgi


docker-compose.yml 있는 위치에서 
vi ecs-params.yml 

version: 1

task_definition:
  task_execution_role: ecsTaskExecutionRole
  ecs_network_mode: awsvpc
  task_size:
    mem_limit: 0.5GB
    cpu_limit: 256
run_params:
  network_configuration:
    awsvpc_configuration:
      subnets:
        - ""
        - ""
      security_groups:
        - ""
      assign_public_ip: ENABLED
services:
  django:
    essential: True
  nginx:
    depends_on:
      -container_name: django


ecs-cli compose --file docker-compose.yml --ecs-params ecs-params.yml service create --launch-type FARGATE
ecs-cli compose --file docker-compose.yml service start



##################################################
AWS KMS(Key Management Service)
##################################################
KMS 는 암호화 키를 관리해주는 서비스 
관리하는 암호화 키를 CMK(Customer Master Key)라고 부름  
CMK를 HSMs(Hardware Security Modules)라는 저장소에 저장 
HSMs에 있는 CMK를 활용하기 위해 KMS API를 사용 
AWS Cloudtrail로 누가 어떤 Key를 어떻게 사용했는지 로그를 남김 

키생성하기 
대칭키
암호화 및 해독
KMS 
단일리전 
키 관리 사용자 
키 사용 사용자 선택 

new EC2에서 
sudo apt update
sudo apt install awscli 
aws configure 키관리자로 설정 
sudo apt install python3-pip 
pip install aws-encrytion-sdk 

vi encrypting.py

import aws_encrytion_sdk
from aws_encrytion_sdk import CommitmentPolicy

client = aws_encrytion_sdk.EncryptionSDKClient(commitment_policy=CommitmentPolicy.REQUIRE_ENCRYPT_REQUIRE_DECRYPT)
key_arn = ""

source_plaintext = 'hi'

kms_kwargs = dict(key_ids=[key_arn])
master_key_provider = aws_encrytion_sdk.StrictAwsKmsMasterKeyProvider(**kms_kwargs)
ciphertext, encryptor_header = client.encrypt(source=source_plaintext, key_provieder=master_key_provider)

print(ciphertext)

cycled_plaintext, decrypted_header = client.decrypt(source=ciphertext, key_provieder=master_key_provider)



##################################################
AWS CodeCommit 
##################################################
IAM 사용자 생성 
administratorAccess 
codecommit fullaccess 
id,key 생성 

사용자 보안자격증명에서 AWS codecommit https git 자격증명 생성, 자격증명 다운로드(user name, password)
ec2에서 aws configure 위에서 생성한 IAM 사용자로 설정 

CodeCommit에서 레포지토리 생성. 
git clone 레포지토리https주소 
다운받은 자격증명의 username, password입력 

레포폴더로 들어가서 
git config --local user.name "hongsa"
git config --local user.email bippr0901@gmail.com 
git init 
git add .
git commit -m "first commit" 
git push -u origin


##################################################
AWS CodeDeploy
##################################################


##################################################
AWS IAM 보안
##################################################
Root 계정
IAM - User, Role 
STS(Security Token Service)


##################################################
부하 테스트
##################################################
npm install loadtest
npm install -g artillery



##################################################
Elastic Beanstalk
##################################################
애플리케이션을 신속하게 배포하고 관리할수 있게 해주는 서비스 
create application -> 앱이름 설정 -> 플랫폼에서는 어떤 언어로된 앱 만들건지 설정 -> 추가옵션에서 키페어 설정, vpc설정하고 앱생성
기본 앱구성환경이 만들어진 ec2가 생성됨. nginx가 기본으로 구성되어있음. 
EB가 다 만들어지면 jar파일을 올려서 java프로젝트를 실행할 수 있음.
