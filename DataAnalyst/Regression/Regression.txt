

### Loss Function 
모델의 에러 수준
Error = Variance + Bias + Noise Data 
Variance : 추정값의 평균과 추정값들 간의 차이. 즉 추정값들의 흩어진 정도 
Bias : 추정값의 평균과 참값들 간의 차이 
Noise Data : Outlier 나 기타 범주에서 벗어난 데이터들 

MSE : 예측값과 실제값의 차이의 제곱을 평균한 것 
제곱한 이유는 미분이 가능하기 때문 미분값이 0이 될때 에러를 최소화 



### 베타계수 추정 법 
베타계수는 독립변수가 변할때 종속변수가 얼마만큼 변하냐에 대한 개념이다. 즉 베타계수는 기울기에 대한 개념. 기울기가 0이라면 독립변수의 변화가 종속변수에 전혀 영향을 못끼치는 것임.
이때 베타계수는 미분을 통해 값을 구하게 된다. 베타계수가 여러개면 편미분을 통해 구하게 된다. 
베타계수를 검증할때는 p-value값을 사용하게되는데 p-value란 독립변수와 종속변수의 관계가 우연히 발생할 확률에 대한 개념이다. 
이때 베타에 대한 p-value가 0.05 이하이여야 베타계수가 신뢰가 있다고 판단한다. 즉 베타계수가 0일 확률이 5%미만이여야지 신뢰가 가능한 것

이때 scale에 대한 개념이 나오는데 예를들어 독립변수가 여러개라고 가정했을때 독립변수마다 값의 범위가 다를것이기 때문에 여러 독립변수간의 중요도에 대한 상대적인 비교가 불가능하게 된다. 이를 해결하기 위해서는 독립변수들의 평균값을 똑같이 맞춰주는 스케일링 작업이 필요하다 

결론적으로 p-value값이 작으면서 베타계수가 높은 것이 중요한 독립변수라고 말할 수 있다. 



### 모델 평가 및 지표 해석 
R스퀘어 : 평균으로 예측한 것에 대비 분산을 얼마나 축소 시켰는지에 대한 판단 
0~1의 값을 갖고, 에러값(실제치-예측값)이 낮으면 낮을 수록 R스퀘어값이 1에 가까워진다. 
보통 현업에서는 R스퀘어 값이 0.25정도만 되도 유의미하다고 판단함. 0.3이상인 경우를 찾기 힘들다고 함 

Regression 모델 평가 척도 
    MAE : 실제 값과 예측 값의 차이 평균 (미분이 불가능하기 때문에 잘 사용하지 않음)
    MAPE : 실제 값과 예측 값의 비율 차이의 평균 
    MSE : 실제 값과 예측 값의 차이를 제곱하고 평균 
    RMSE : MSE의 제곱근 

** 요약 
    model의 성능을 R스퀘어 또는 모델 평가 척도로 평가 -> 모델 성능이 안좋으면 Data 퀄리트를 체크해봐야한다. 
    p-value를 통해 의미있는 독립변수 추출 
    스케일링 전에는 베타계수를 통해 독립변수가 종속변수에 끼치는 영향도를 알아내고, 스케일링 후에는 독립변수들간의 중요성을 비교해볼 수 있다. 




### Feature selection 
Feature(독립변수)가 많아질수록 모델 복잡도는 높아진다. 
모델 복잡도가 높아질수록 bias는 낮아지지만 Variance가 높아진다. 
모델 복잡도가 높다는것은 Overfitting이 되었다는 뜻이고 이를 방지하기 위해서는 Feature Selection이 필요하다. (복잡도를 줄일 필요가있다.)

기법 
    완전탐색 : 독립변수가 P개있다고 가정했을때 모델의 경우의 수는 2^P - 1 개이고, 이에 대한 모델평가를 다 해보는 것. Train Set이 아닌 Test Set으로 모델 평가를 진행 
            하지만 이방법은 독립변수가 많을수록 시간이 기하급수적으로 늘어나기때문에 사용하지 않음 

    Forward-selection : 독립변수가 5개 있으면, 하나씩 넣어서 모델평가를 진행 그중에 가장 평가가 좋은 변수를 선택함
                        이후 선택한 변수를 포함해서 나머지 변수를 하나씩 넣어보고 다시 모델 평가 진행. 가장 평가가 좋은 변수 선택 
                        이런식으로 반복하다가 평가점수가 같거나 낮게 나오면 멈춤. 

    backword-selection : 이번엔 모든 독립변수를 넣어놓고 모델을 평가함 
                         이후 변수를 하나씩 빼보면서 모델을 평가, 평가점수가 같거나 높으면 계속 진행 
                         평가점수가 낮아지면 멈춤.

    stepwise-selection : forward와 backword를 번갈아 가며 수행함. 최적의 모델을 찾을 확률이 높아짐.

    위의 기법들은 모두 독립변수 간의 상관성을 무시한 기법이기 때문에 현재는 사용하지 않는 기법이라고 할 수 있다. 
    이제는 독립변수간의 상관성도 고려하는 기법인 Ridge : penalt term 기법을 사용한다. 
    ** Penalty Term : 에러값이 최소가 되는 점에서 베타계수 값이 결정되는데 미분과정에서 penalt항을 추가하게 되면 베타계수 값은 작아지게 된다. 
                      베타계수가 작아진다는 것은 종속변수에 미치는 영향이 작아진다는 뜻이고 이 원리를 통해 불필요한 Feature에 대해서 베타계수를 0에 수렴하게 만들어
                      종속변수에 영향을 못끼치게 만드는 것이다. 

                      Ridge 기법은 다중공선성을 방지할 수 있다. 
                      
    ** Penalty Term을 적용할 때 중요한 것은 Feature간의 Scaling이 필수이다. 왜냐하면 똑같은 페널티를 주더라도 독립변수간의 페널티 영향이 다르기 때문이다. 

    Ridge 
        L1-norm 
        L2-norm 